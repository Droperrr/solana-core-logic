#!/usr/bin/env python3
"""
–§–∞–∑–∞ 1: –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–æ—Ü–µ–¥—É—Ä (SOP) 
–Ω–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""
import sqlite3
import pandas as pd
from collections import Counter, defaultdict
import json

def analyze_sop_patterns():
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –≥—Ä—É–ø–ø—ã
    –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    """
    print("=" * 80)
    print("–§–ê–ó–ê 1: –ê–ù–ê–õ–ò–ó –°–¢–ê–ù–î–ê–†–¢–ù–´–• –û–ü–ï–†–ê–¶–ò–û–ù–ù–´–• –ü–†–û–¶–ï–î–£–† (SOP)")
    print("=" * 80)
    
    conn = sqlite3.connect('db/solana_db.sqlite')
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
    print("üìä –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è...")
    
    query = '''
    SELECT 
        e.signature,
        e.block_time,
        e.semantic_event_type,
        e.transaction_role,
        e.is_infrastructure,
        e.is_trading_related,
        e.program_category,
        e.token_a_mint,
        e.token_b_mint,
        e.from_wallet,
        e.to_wallet,
        t.source_query_address as token_address
    FROM enhanced_ml_events e
    JOIN transactions t ON e.signature = t.signature
    ORDER BY e.block_time, e.id
    '''
    
    df = pd.read_sql_query(query, conn)
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π")
    print(f"üìù –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {df['signature'].nunique():,}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–æ–∫–µ–Ω–∞–º
    print(f"\nü™ô –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –¢–û–ö–ï–ù–ê–ú:")
    token_stats = df['token_address'].value_counts()
    for token, count in token_stats.items():
        print(f"  {token}: {count:,} —Å–æ–±—ã—Ç–∏–π")
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–û–°–¢–ï–ô –û–ü–ï–†–ê–¶–ò–ô...")
    
    sequences = df.groupby('signature').agg({
        'semantic_event_type': lambda x: ' -> '.join(x),
        'block_time': 'first',
        'token_address': 'first',
        'is_infrastructure': lambda x: sum(x),
        'is_trading_related': lambda x: sum(x)
    }).reset_index()
    
    sequences.columns = ['signature', 'sequence_pattern', 'block_time', 'token_address', 'infra_count', 'trading_count']
    
    print(f"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(sequences):,} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    
    # –ê–Ω–∞–ª–∏–∑ –æ–±—â–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    print(f"\nüìà –¢–û–ü-15 –°–ê–ú–´–• –ß–ê–°–¢–´–• –û–ü–ï–†–ê–¶–ò–û–ù–ù–´–• –ü–†–û–¶–ï–î–£–†:")
    print("-" * 70)
    
    sequence_counts = sequences['sequence_pattern'].value_counts()
    total_transactions = len(sequences)
    
    for i, (pattern, count) in enumerate(sequence_counts.head(15).items(), 1):
        percentage = (count / total_transactions) * 100
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ–ø–µ—Ä–∞—Ü–∏–∏
        if 'SWAP' in pattern or 'TOKEN_SWAP' in pattern:
            operation_type = "üîÑ –¢–û–†–ì–û–í–õ–Ø"
        elif 'TRANSFER' in pattern or 'TOKEN_TRANSFER' in pattern:
            operation_type = "üì§ –ü–ï–†–ï–í–û–î"
        elif 'INFRASTRUCTURE' in pattern:
            operation_type = "üîß –ò–ù–§–†–ê–°–¢–†–£–ö–¢–£–†–ê"
        else:
            operation_type = "‚ùì –°–ú–ï–®–ê–ù–ù–´–ô"
        
        print(f"{i:2d}. {operation_type} ({count:3d} —Ä–∞–∑, {percentage:5.1f}%)")
        print(f"    üìã {pattern}")
        print()
    
    # –ê–Ω–∞–ª–∏–∑ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–µ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
    if not sequence_counts.empty:
        most_common_pattern = sequence_counts.index[0]
        most_common_count = sequence_counts.iloc[0]
        dominance_ratio = most_common_count / total_transactions
        
        print(f"üéØ –ê–ù–ê–õ–ò–ó –î–û–ú–ò–ù–ò–†–£–Æ–©–ï–ì–û –ü–ê–¢–¢–ï–†–ù–ê:")
        print("-" * 50)
        print(f"–°–∞–º–∞—è —á–∞—Å—Ç–∞—è SOP: '{most_common_pattern}'")
        print(f"–í—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è: {most_common_count} –∏–∑ {total_transactions} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π ({dominance_ratio:.1%})")
        
        if dominance_ratio > 0.5:
            print("‚úÖ –í–´–í–û–î: –≠—Ç–æ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω - '–Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ' –ø–æ–≤–µ–¥–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã")
        elif dominance_ratio > 0.3:
            print("‚ö†Ô∏è  –í–´–í–û–î: –ß–∞—Å—Ç—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω, –Ω–æ –µ—Å—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ")
        else:
            print("üîç –í–´–í–û–î: –í—ã—Å–æ–∫–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ - –Ω—É–∂–µ–Ω –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
    
    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Ç–æ–∫–µ–Ω–∞–º
    print(f"\nüî¨ –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–û –¢–û–ö–ï–ù–ê–ú:")
    print("-" * 60)
    
    for token in token_stats.index:
        token_sequences = sequences[sequences['token_address'] == token]
        token_patterns = token_sequences['sequence_pattern'].value_counts()
        
        print(f"\nü™ô –¢–æ–∫–µ–Ω: {token}")
        print(f"   –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {len(token_sequences):,}")
        print(f"   –¢–æ–ø-5 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤:")
        
        for i, (pattern, count) in enumerate(token_patterns.head(5).items(), 1):
            percentage = (count / len(token_sequences)) * 100
            print(f"   {i}. {pattern} ({count} —Ä–∞–∑, {percentage:.1f}%)")
    
    # –ü–æ–∏—Å–∫ –º–µ–∂—Ç–æ–∫–µ–Ω–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    print(f"\nüîÑ –ê–ù–ê–õ–ò–ó –ú–ï–ñ–¢–û–ö–ï–ù–ù–´–• –°–û–í–ü–ê–î–ï–ù–ò–ô (SOP FINGERPRINT):")
    print("-" * 70)
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-5 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
    token_top_patterns = {}
    for token in token_stats.index:
        token_sequences = sequences[sequences['token_address'] == token]
        token_patterns = token_sequences['sequence_pattern'].value_counts().head(5)
        token_top_patterns[token] = set(token_patterns.index)
    
    # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
    if len(token_top_patterns) >= 2:
        tokens = list(token_top_patterns.keys())
        common_patterns = token_top_patterns[tokens[0]]
        
        for token in tokens[1:]:
            common_patterns = common_patterns.intersection(token_top_patterns[token])
        
        print(f"üéØ –û–ë–©–ò–ï –ü–ê–¢–¢–ï–†–ù–´ –í –¢–û–ü-5 –£ –í–°–ï–• –¢–û–ö–ï–ù–û–í:")
        if common_patterns:
            for pattern in common_patterns:
                print(f"   ‚úÖ {pattern}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–æ–∫–µ–Ω–∞–º –¥–ª—è —ç—Ç–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
                for token in tokens:
                    token_sequences = sequences[sequences['token_address'] == token]
                    pattern_count = (token_sequences['sequence_pattern'] == pattern).sum()
                    total_token_tx = len(token_sequences)
                    percentage = (pattern_count / total_token_tx) * 100
                    print(f"      {token}: {pattern_count} —Ä–∞–∑ ({percentage:.1f}%)")
            
            print(f"\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –í–´–í–û–î:")
            print(f"   –ù–∞–π–¥–µ–Ω–æ {len(common_patterns)} –æ–±—â–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ —Ç–æ–ø-5 —É –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤!")
            print(f"   –≠—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –°–¢–ê–ù–î–ê–†–¢–ò–ó–ò–†–û–í–ê–ù–ù–£–Æ –û–ü–ï–†–ê–¶–ò–û–ù–ù–£–Æ –ü–†–û–¶–ï–î–£–†–£!")
        else:
            print("   ‚ùå –û–±—â–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ —Ç–æ–ø-5 –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –ü–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
    print(f"\nüïµÔ∏è –ü–û–ò–°–ö –ê–ù–û–ú–ê–õ–¨–ù–´–• –¢–†–ê–ù–ó–ê–ö–¶–ò–ô:")
    print("-" * 50)
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã, –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Ç–æ–ª—å–∫–æ 1-2 —Ä–∞–∑–∞ - –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
    rare_patterns = sequence_counts[sequence_counts <= 2]
    
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(rare_patterns)} —Ä–µ–¥–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (‚â§2 —Ä–∞–∑):")
    
    for pattern, count in rare_patterns.head(10).items():
        print(f"   {count}x: {pattern}")
        
        # –ù–∞—Ö–æ–¥–∏–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —Å —ç—Ç–∏–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
        anomaly_transactions = sequences[sequences['sequence_pattern'] == pattern]
        for _, tx in anomaly_transactions.iterrows():
            print(f"      üîç {tx['signature']} (—Ç–æ–∫–µ–Ω: {tx['token_address']})")
    
    # –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑
    print(f"\nüìÖ –í–†–ï–ú–ï–ù–ù–û–ô –ê–ù–ê–õ–ò–ó –ü–ê–¢–¢–ï–†–ù–û–í:")
    print("-" * 40)
    
    sequences['hour'] = pd.to_datetime(sequences['block_time'], unit='s').dt.hour
    hourly_patterns = sequences.groupby('hour')['sequence_pattern'].value_counts()
    
    print("–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —á–∞—Å–∞–º (—Ç–æ–ø –ø–∞—Ç—Ç–µ—Ä–Ω):")
    for hour in range(24):
        if hour in hourly_patterns.index.get_level_values(0):
            hour_data = hourly_patterns[hour]
            if not hour_data.empty:
                top_pattern = hour_data.index[0]
                count = hour_data.iloc[0]
                print(f"   {hour:2d}:00 - {top_pattern} ({count} —Ä–∞–∑)")
    
    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
    print(f"\nüìã –°–í–û–î–ù–´–ô –û–¢–ß–ï–¢ - –ü–û–ò–°–ö SOP:")
    print("=" * 60)
    
    print(f"‚úÖ –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   - –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {total_transactions:,}")
    print(f"   - –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(sequence_counts):,}")
    print(f"   - –¢–æ–∫–µ–Ω–æ–≤: {len(token_stats)}")
    
    print(f"\nüéØ –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã:")
    if dominance_ratio > 0.3:
        print(f"   ‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω ({dominance_ratio:.1%} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π)")
        print(f"   ‚úÖ –ì—Ä—É–ø–ø–∞ —Å–ª–µ–¥—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø—Ä–æ—Ü–µ–¥—É—Ä–µ")
    
    if common_patterns:
        print(f"   üö® –ù–∞–π–¥–µ–Ω–æ {len(common_patterns)} –æ–±—â–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏")
        print(f"   üö® –í–´–°–û–ö–ê–Ø –í–ï–†–û–Ø–¢–ù–û–°–¢–¨ –ö–û–û–†–î–ò–ù–ò–†–û–í–ê–ù–ù–´–• –î–ï–ô–°–¢–í–ò–ô")
    
    print(f"   üìä –†–µ–¥–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–∞–Ω–æ–º–∞–ª–∏–π): {len(rare_patterns)}")
    
    conn.close()
    
    print(f"\nüéâ –§–ê–ó–ê 1 –ó–ê–í–ï–†–®–ï–ù–ê!")
    print(f"üìà –ì–æ—Ç–æ–≤—ã –∫ –§–∞–∑–µ 2: –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π –≤ SOP")

if __name__ == "__main__":
    analyze_sop_patterns() 