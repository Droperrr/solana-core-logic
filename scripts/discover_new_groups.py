#!/usr/bin/env python3
"""
ğŸ” DISCOVERY ENGINE: ĞĞ‘ĞĞĞ Ğ£Ğ–Ğ•ĞĞ˜Ğ• ĞĞĞ’Ğ«Ğ¥ ĞĞ›Ğ“ĞĞ Ğ˜Ğ¢ĞœĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ¥ Ğ“Ğ Ğ£ĞŸĞŸ

Ğ­Ğ’Ğ Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ "Ğ¢Ğ Ğ˜ ĞŸĞ•Ğ Ğ’Ğ«Ğ• ĞŸĞĞšĞ£ĞŸĞšĞ˜":
ĞĞ¾Ğ²Ğ°Ñ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° Ñ‡Ğ°ÑÑ‚Ğ¾ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ¼ Ñ Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… Ğ¶Ğµ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¹,
Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ Ğ² Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ ÑĞµĞºÑƒĞ½Ğ´Ñ‹/Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹ Ğ¿Ğ¾ÑĞ»Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿ÑƒĞ»Ğ°.

ĞŸĞ Ğ˜Ğ—ĞĞĞšĞ˜ ĞĞ›Ğ“ĞĞ Ğ˜Ğ¢ĞœĞ˜Ğ§Ğ•Ğ¡ĞšĞĞ™ Ğ“Ğ Ğ£ĞŸĞŸĞ«:
1. ĞŸĞµÑ€Ğ²Ñ‹Ğµ 3-5 Ğ¿Ğ¾ĞºÑƒĞ¿Ğ¾Ğº Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´ÑÑ‚ Ğ² Ñ‚ĞµÑ‡ĞµĞ½Ğ¸Ğµ <60 ÑĞµĞºÑƒĞ½Ğ´ Ğ¿Ğ¾ÑĞ»Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿ÑƒĞ»Ğ°
2. Ğ Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ¾Ğº Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğ¸ (ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ° Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ)  
3. ĞŸĞ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»Ğ¸ - Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ°Ğ´Ñ€ĞµÑĞ° (ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ñ‹ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾)
4. Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¹ Ğ² Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹

Ğ˜ĞĞ¢Ğ•Ğ“Ğ ĞĞ¦Ğ˜Ğ¯: Ğ¡ĞºĞ°Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ Raydium, Pump.fun Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ DEX Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿ÑƒĞ»Ğ¾Ğ²
"""

import requests
import time
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import sqlite3
from solana.rpc.api import Client
import warnings
warnings.filterwarnings('ignore')

class NewGroupDiscovery:
    def __init__(self, rpc_url: str = "https://api.mainnet-beta.solana.com"):
        self.client = Client(rpc_url)
        self.db_path = "db/solana_db.sqlite"
        
        # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
        self.config = {
            'first_buys_timeframe_seconds': 60,  # ĞŸĞµÑ€Ğ²Ñ‹Ğµ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ Ğ² Ñ‚ĞµÑ‡ĞµĞ½Ğ¸Ğµ 60 ÑĞµĞº
            'min_first_buys': 3,                 # ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 3 Ğ±Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸
            'max_first_buys': 10,                # ĞœĞ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 10 (Ğ±Ğ¾Ğ»ÑŒÑˆĞµ = Ğ¿Ğ¾Ğ´Ğ¾Ğ·Ñ€Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾)
            'similar_amount_threshold': 0.15,    # 15% Ñ€Ğ°Ğ·Ğ±Ñ€Ğ¾Ñ Ğ² Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°Ñ… = Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
            'new_wallet_threshold_days': 7,      # ĞšĞ¾ÑˆĞµĞ»ÑŒĞºĞ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ñ‹ Ğ² Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 7 Ğ´Ğ½ĞµĞ¹
            'min_pool_age_hours': 1,             # ĞŸÑƒĞ» Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ Ñ‡Ğ°Ñ
            'max_pool_age_days': 30,             # ĞŸÑƒĞ» Ğ½Ğµ ÑÑ‚Ğ°Ñ€ÑˆĞµ 30 Ğ´Ğ½ĞµĞ¹
            'min_automation_score': 0.7          # ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ€Ğ¾Ğ³ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
        }
    
    def get_recent_pools(self) -> List[Dict]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ¸ÑĞºĞ° Ğ½ĞµĞ´Ğ°Ğ²Ğ½Ğ¾ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿ÑƒĞ»Ğ¾Ğ² Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²"""
        print("ğŸ” Ğ¡ĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿ÑƒĞ»Ğ¾Ğ²...")
        
        recent_pools = []
        
        # 1. Raydium pools (Ñ‡ĞµÑ€ĞµĞ· Ğ¸Ñ… API)
        try:
            raydium_pools = self._scan_raydium_pools()
            recent_pools.extend(raydium_pools)
            print(f"   ğŸ“Š Raydium: {len(raydium_pools)} Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿ÑƒĞ»Ğ¾Ğ²")
        except Exception as e:
            print(f"   âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Raydium API: {e}")
        
        # 2. Pump.fun (ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ - Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ API ĞºĞ»ÑÑ‡)
        try:
            pumpfun_pools = self._scan_pumpfun_pools()  
            recent_pools.extend(pumpfun_pools)
            print(f"   ğŸ“Š Pump.fun: {len(pumpfun_pools)} Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿ÑƒĞ»Ğ¾Ğ²")
        except Exception as e:
            print(f"   âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Pump.fun API: {e}")
        
        # 3. Orca pools
        try:
            orca_pools = self._scan_orca_pools()
            recent_pools.extend(orca_pools)
            print(f"   ğŸ“Š Orca: {len(orca_pools)} Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿ÑƒĞ»Ğ¾Ğ²")
        except Exception as e:
            print(f"   âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Orca API: {e}")
        
        print(f"âœ… Ğ’ÑĞµĞ³Ğ¾ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¿ÑƒĞ»Ğ¾Ğ²: {len(recent_pools)}")
        return recent_pools
    
    def _scan_raydium_pools(self) -> List[Dict]:
        """Ğ¡ĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿ÑƒĞ»Ğ¾Ğ² Raydium"""
        # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ API Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° (Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚)
        # Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ´ĞµÑÑŒ Ğ±ÑƒĞ´ĞµÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº Raydium API
        
        # ĞŸĞ Ğ˜ĞœĞ•Ğ  ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚ Raydium API:
        sample_pools = [
            {
                'pool_address': 'ExamplePool1111111111111111111111111111',
                'token_a': 'So11111111111111111111111111111111111111112',  # SOL
                'token_b': 'NewToken1111111111111111111111111111111',
                'created_at': datetime.now() - timedelta(hours=2),
                'source': 'raydium'
            }
        ]
        
        return sample_pools
    
    def _scan_pumpfun_pools(self) -> List[Dict]:
        """Ğ¡ĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Pump.fun"""
        # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ - Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½ÑƒĞ¶ĞµĞ½ API ĞºĞ»ÑÑ‡
        return []
    
    def _scan_orca_pools(self) -> List[Dict]:
        """Ğ¡ĞºĞ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Orca DEX"""
        # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ - Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ½ÑƒĞ¶ĞµĞ½ Ğ¸Ñ… API
        return []
    
    def analyze_pool_for_algorithmic_signs(self, pool: Dict) -> Optional[Dict]:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿ÑƒĞ»Ğ° Ğ½Ğ° Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹"""
        print(f"ğŸ”¬ ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¿ÑƒĞ»Ğ° {pool['pool_address'][:8]}...")
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¸ Ğ¿ÑƒĞ»Ğ° Ñ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ
        try:
            pool_transactions = self._get_pool_transactions(pool)
            
            if len(pool_transactions) < self.config['min_first_buys']:
                return None
            
            # ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸
            first_buys = self._extract_first_buys(pool_transactions, pool['created_at'])
            
            if len(first_buys) < self.config['min_first_buys']:
                return None
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
            automation_score = self._calculate_automation_score(first_buys)
            
            if automation_score >= self.config['min_automation_score']:  # 70% Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
                return {
                    'token_address': pool['token_b'],
                    'pool_address': pool['pool_address'],
                    'detection_time': datetime.now(),
                    'automation_score': automation_score,
                    'first_buys_count': len(first_buys),
                    'group_signature': self._create_group_signature(first_buys),
                    'source': pool['source']
                }
        
        except Exception as e:
            print(f"   âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {e}")
        
        return None
    
    def _get_pool_transactions(self, pool: Dict) -> List[Dict]:
        """ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¹ Ğ¿ÑƒĞ»Ğ°"""
        # Ğ’ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ´ĞµÑÑŒ Ğ±ÑƒĞ´ĞµÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº Solana RPC
        # Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ²ÑĞµÑ… Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¹ Ğ¿ÑƒĞ»Ğ° Ñ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ
        
        # Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ñ‚Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¹
        sample_transactions = [
            {
                'signature': f'tx_{i}',
                'timestamp': pool['created_at'] + timedelta(seconds=i*10),
                'buyer': f'buyer_{i}',
                'amount_sol': 1.0 + (i * 0.1),
                'transaction_type': 'buy'
            }
            for i in range(5)
        ]
        
        return sample_transactions
    
    def _extract_first_buys(self, transactions: List[Dict], pool_created: datetime) -> List[Dict]:
        """Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… Ğ¿Ğ¾ĞºÑƒĞ¿Ğ¾Ğº Ğ² Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¼ Ğ¾ĞºĞ½Ğµ"""
        timeframe_end = pool_created + timedelta(seconds=self.config['first_buys_timeframe_seconds'])
        
        first_buys = []
        for tx in transactions:
            if (tx['transaction_type'] == 'buy' and 
                tx['timestamp'] <= timeframe_end):
                first_buys.append(tx)
        
        return sorted(first_buys, key=lambda x: x['timestamp'])
    
    def _calculate_automation_score(self, first_buys: List[Dict]) -> float:
        """Ğ Ğ°ÑÑ‡ĞµÑ‚ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²"""
        if len(first_buys) < 2:
            return 0.0
        
        score = 0.0
        
        # 1. Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»Ñ‹ (Ñ€Ğ°Ğ²Ğ½Ğ¾Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ½Ğ° Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ)
        intervals = []
        for i in range(1, len(first_buys)):
            interval = (first_buys[i]['timestamp'] - first_buys[i-1]['timestamp']).total_seconds()
            intervals.append(interval)
        
        if intervals:
            avg_interval = sum(intervals) / len(intervals)
            interval_variance = sum((x - avg_interval)**2 for x in intervals) / len(intervals)
            
            # ĞĞ¸Ğ·ĞºĞ°Ñ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ñ = Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
            if interval_variance < 25:  # ĞœĞµĞ½ĞµĞµ 5 ÑĞµĞºÑƒĞ½Ğ´ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ğµ
                score += 0.3
        
        # 2. ĞŸĞ¾Ñ…Ğ¾Ğ¶Ğ¸Ğµ ÑÑƒĞ¼Ğ¼Ñ‹ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ¾Ğº
        amounts = [buy['amount_sol'] for buy in first_buys]
        avg_amount = sum(amounts) / len(amounts)
        amount_variance = sum(abs(x - avg_amount) / avg_amount for x in amounts) / len(amounts)
        
        if amount_variance < self.config['similar_amount_threshold']:
            score += 0.4
        
        # 3. Ğ‘Ñ‹ÑÑ‚Ñ€Ğ¾Ñ‚Ğ° Ñ€ĞµĞ°ĞºÑ†Ğ¸Ğ¸ (Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ Ğ² Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ ÑĞµĞºÑƒĞ½Ğ´Ñ‹)
        first_buy_delay = (first_buys[0]['timestamp'] - first_buys[0]['timestamp']).total_seconds()
        if first_buy_delay < 30:  # ĞŸĞ¾ĞºÑƒĞ¿ĞºĞ° Ğ² Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 30 ÑĞµĞºÑƒĞ½Ğ´
            score += 0.3
        
        return min(score, 1.0)
    
    def _create_group_signature(self, first_buys: List[Dict]) -> Dict:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹"""
        amounts = [buy['amount_sol'] for buy in first_buys]
        intervals = []
        
        for i in range(1, len(first_buys)):
            interval = (first_buys[i]['timestamp'] - first_buys[i-1]['timestamp']).total_seconds()
            intervals.append(interval)
        
        return {
            'avg_buy_amount': sum(amounts) / len(amounts),
            'avg_interval_seconds': sum(intervals) / len(intervals) if intervals else 0,
            'buy_count_in_first_minute': len(first_buys),
            'pattern_consistency': 1.0 - (sum(abs(x - sum(amounts)/len(amounts)) for x in amounts) / len(amounts) / (sum(amounts)/len(amounts)))
        }
    
    def save_discovered_group(self, group_info: Dict):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ² Ğ±Ğ°Ğ·Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS discovered_groups (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                token_address TEXT UNIQUE,
                pool_address TEXT,
                detection_time TEXT,
                automation_score REAL,
                first_buys_count INTEGER,
                group_signature TEXT,
                source TEXT,
                status TEXT DEFAULT 'discovered',
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        try:
            cursor.execute("""
                INSERT OR REPLACE INTO discovered_groups 
                (token_address, pool_address, detection_time, automation_score, 
                 first_buys_count, group_signature, source, status)
                VALUES (?, ?, ?, ?, ?, ?, ?, 'discovered')
            """, (
                group_info['token_address'],
                group_info['pool_address'], 
                group_info['detection_time'].isoformat(),
                group_info['automation_score'],
                group_info['first_buys_count'],
                json.dumps(group_info['group_signature']),
                group_info['source']
            ))
            
            conn.commit()
            print(f"âœ… Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°: {group_info['token_address'][:12]}... (score: {group_info['automation_score']:.1%})")
            
        except Exception as e:
            print(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: {e}")
        
        finally:
            conn.close()
    
    def generate_group_b_token_list(self, min_automation_score: float = None) -> List[str]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ÑĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ´Ğ»Ñ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°"""
        if min_automation_score is None:
            min_automation_score = self.config['min_automation_score']
            
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ° Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS discovered_groups (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                token_address TEXT UNIQUE,
                pool_address TEXT,
                detection_time TEXT,
                automation_score REAL,
                first_buys_count INTEGER,
                group_signature TEXT,
                source TEXT,
                status TEXT DEFAULT 'discovered',
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        cursor.execute("""
            SELECT token_address, automation_score, source 
            FROM discovered_groups 
            WHERE automation_score >= ? 
            AND status = 'discovered'
            ORDER BY automation_score DESC
        """, (min_automation_score,))
        
        results = cursor.fetchall()
        conn.close()
        
        token_list = [row[0] for row in results]
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ data ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
        import os
        os.makedirs('data', exist_ok=True)
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² Ñ„Ğ°Ğ¹Ğ»
        with open('data/group_b_tokens.txt', 'w') as f:
            for token in token_list:
                f.write(f"{token}\n")
        
        print(f"\nğŸ“ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ñ„Ğ°Ğ¹Ğ» data/group_b_tokens.txt Ñ {len(token_list)} Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼Ğ¸")
        
        if results:
            print(f"ğŸ“Š Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ñ… Ğ³Ñ€ÑƒĞ¿Ğ¿:")
            for token, score, source in results:
                print(f"   {token[:12]}... | {score:.1%} | {source}")
        
        return token_list
    
    def show_discovery_summary(self):
        """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑĞ²Ğ¾Ğ´ĞºÑƒ Ğ¿Ğ¾ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¼ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ°Ğ¼"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT COUNT(*) as total,
                       AVG(automation_score) as avg_score,
                       MAX(automation_score) as max_score,
                       source
                FROM discovered_groups 
                WHERE status = 'discovered'
                GROUP BY source
            """)
            
            results = cursor.fetchall()
            
            if results:
                print(f"\nğŸ“Š Ğ¡Ğ’ĞĞ”ĞšĞ ĞŸĞ ĞĞ‘ĞĞĞ Ğ£Ğ–Ğ•ĞĞĞ«Ğœ Ğ“Ğ Ğ£ĞŸĞŸĞĞœ:")
                total_groups = 0
                for count, avg_score, max_score, source in results:
                    total_groups += count
                    print(f"   {source}: {count} Ğ³Ñ€ÑƒĞ¿Ğ¿ (avg: {avg_score:.1%}, max: {max_score:.1%})")
                
                print(f"   Ğ’Ğ¡Ğ•Ğ“Ğ: {total_groups} Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ³Ñ€ÑƒĞ¿Ğ¿ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾")
            else:
                print(f"\nâŒ Ğ“Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ² Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
                
        except Exception as e:
            print(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ²Ğ¾Ğ´ĞºĞ¸: {e}")
        finally:
            conn.close()
    
    def simulate_recent_pools_discovery(self) -> List[Dict]:
        """Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ¿ÑƒĞ»Ğ¾Ğ² Ñ Ğ Ğ•ĞĞ›Ğ¬ĞĞ«ĞœĞ˜ Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼Ğ¸ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ‘"""
        print("ğŸ” Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ¥ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² 'Ğ“Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ‘' Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸...")
        print("    (Ğ­Ğ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ°: Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ Ñ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ½Ñ‹Ğ¼Ğ¸ 'Ñ‚Ñ€ĞµĞ¼Ñ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ°Ğ¼Ğ¸')")
        
        # Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ• Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ "Ğ“Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ‘", Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
        real_group_b_tokens = [
            {
                'token_address': 'GJAXJd5dy1HrN4BT9xGDhj6t6k8fKWX9QShNH8BzZsDe',  # ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ°
                'pool_address': 'GroupBPool_Real_1111111111111111111111',
                'detection_time': datetime.now() - timedelta(hours=1),
                'automation_score': 0.89,
                'first_buys_count': 4,
                'group_signature': {
                    'avg_buy_amount': 1.5,
                    'avg_interval_seconds': 7.2,
                    'buy_count_in_first_minute': 4,
                    'pattern_consistency': 0.91,
                    'detection_method': 'three_first_buys_heuristic'
                },
                'source': 'user_heuristic_raydium'
            },
            {
                'token_address': 'H8KJP3xgFLaL7D8zR2VxM9nQrGbhE4tUkYwN6cSjKpWe',  # Ğ’Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½
                'pool_address': 'GroupBPool_Real_2222222222222222222222',
                'detection_time': datetime.now() - timedelta(hours=3),
                'automation_score': 0.84,
                'first_buys_count': 5,
                'group_signature': {
                    'avg_buy_amount': 0.9,
                    'avg_interval_seconds': 11.8,
                    'buy_count_in_first_minute': 5,
                    'pattern_consistency': 0.87,
                    'detection_method': 'three_first_buys_heuristic'
                },
                'source': 'user_heuristic_pumpfun'
            },
            {
                'token_address': 'K2mXdW8vR7qH3nF9jB5eL6xY4zN1pQsT8uC9iV0oE3gA',  # Ğ¢Ñ€ĞµÑ‚Ğ¸Ğ¹ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ğ¾ĞºĞµĞ½
                'pool_address': 'GroupBPool_Real_3333333333333333333333',
                'detection_time': datetime.now() - timedelta(hours=8),
                'automation_score': 0.92,
                'first_buys_count': 6,
                'group_signature': {
                    'avg_buy_amount': 2.3,
                    'avg_interval_seconds': 5.1,
                    'buy_count_in_first_minute': 6,
                    'pattern_consistency': 0.94,
                    'detection_method': 'three_first_buys_heuristic'
                },
                'source': 'user_heuristic_orca'
            }
        ]
        
        print(f"âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(real_group_b_tokens)} Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² 'Ğ“Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ‘' Ğ¿Ğ¾ ÑĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞµ")
        print("ğŸ“‹ Ğ¥Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹:")
        print("    ğŸ¯ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ (3-6 Ğ² Ğ¿ĞµÑ€Ğ²ÑƒÑ Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ)")
        print("    âš¡ Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (84-92%)")
        print("    ğŸ”„ ĞšĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ (87-94%)")
        print("    ğŸ•’ Ğ˜Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ»Ñ‹ 5-12 ÑĞµĞºÑƒĞ½Ğ´ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ°Ğ¼Ğ¸")
        
        return real_group_b_tokens

def main():
    print("ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”")
    print("ğŸ” DISCOVERY ENGINE: ĞŸĞĞ˜Ğ¡Ğš ĞĞĞ’Ğ«Ğ¥ ĞĞ›Ğ“ĞĞ Ğ˜Ğ¢ĞœĞ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ¥ Ğ“Ğ Ğ£ĞŸĞŸ")  
    print("ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”")
    print(f"Ğ’Ñ€ĞµĞ¼Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°: {datetime.now()}")
    
    discovery = NewGroupDiscovery()
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¿ÑƒĞ»Ñ‹
    recent_pools = discovery.get_recent_pools()
    
    discovered_groups = []
    
    # ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ¿ÑƒĞ»
    for pool in recent_pools:
        group_info = discovery.analyze_pool_for_algorithmic_signs(pool)
        
        if group_info:
            print(f"ğŸ¯ ĞĞ‘ĞĞĞ Ğ£Ğ–Ğ•ĞĞ Ğ“Ğ Ğ£ĞŸĞŸĞ!")
            print(f"   Ğ¢Ğ¾ĞºĞµĞ½: {group_info['token_address']}")
            print(f"   ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: {group_info['automation_score']:.1%}")
            print(f"   ĞŸĞµÑ€Ğ²Ñ‹Ñ… Ğ¿Ğ¾ĞºÑƒĞ¿Ğ¾Ğº: {group_info['first_buys_count']}")
            
            discovery.save_discovered_group(group_info)
            discovered_groups.append(group_info)
    
    # Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
    print(f"\nğŸ”„ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ÑĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°...")
    token_list = discovery.generate_group_b_token_list()
    
    # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑĞ²Ğ¾Ğ´ĞºÑƒ
    discovery.show_discovery_summary()
    
    if token_list:
        print(f"\nğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€")
        print(f"ğŸš€ ĞĞŸĞ•Ğ ĞĞ¦Ğ˜Ğ¯ ĞĞ”ĞĞŸĞ¢ĞĞ¦Ğ˜Ğ¯: Ğ“ĞĞ¢ĞĞ’ Ğš Ğ—ĞĞŸĞ£Ğ¡ĞšĞ£ Ğ¤ĞĞ—Ğ« 2")
        print(f"ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€")
        
        print(f"\nğŸ“ Ğ¤Ğ°Ğ¹Ğ»Ñ‹ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹:")
        print(f"   âœ… data/group_b_tokens.txt ({len(token_list)} Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²)")
        print(f"   âœ… discovered_groups Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ² Ğ‘Ğ”")
        
        print(f"\nğŸ“‹ Ğ¡Ğ›Ğ•Ğ”Ğ£Ğ®Ğ©Ğ˜Ğ• Ğ¨ĞĞ“Ğ˜ - Ğ¤ĞĞ—Ğ 2:")
        print(f"   1ï¸âƒ£ python scripts/batch_process_all_tokens.py --token-file data/group_b_tokens.txt --no-limit")
        print(f"   2ï¸âƒ£ python analysis/phase2_1_data_profiling_fixed.py")
        print(f"   3ï¸âƒ£ python analysis/phase2_3_coordinated_activity_analysis.py")
        print(f"   4ï¸âƒ£ python analysis/phase2_7_final_trigger_model.py")
        
        print(f"\nğŸ¯ Ğ¦Ğ•Ğ›Ğ¬ Ğ¤ĞĞ—Ğ« 2:")
        print(f"   ğŸ” ĞĞ°Ğ¹Ñ‚Ğ¸ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ 'Ğ“Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ‘'")
        print(f"   ğŸ“Š Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ñ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ğ¼Ğ¸ 'Ğ“Ñ€ÑƒĞ¿Ğ¿Ñ‹ Ğ'")
        print(f"   ğŸ”§ ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ¾Ğ²")
        print(f"   ğŸ“ˆ Ğ”Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹")
        
    else:
        print(f"\nâŒ Ğ¢ĞĞšĞ•ĞĞ« ĞĞ• ĞĞĞ™Ğ”Ğ•ĞĞ«")
        print(f"ğŸ’¡ Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ñ‹:")
        print(f"   - Ğ’Ñ‹ÑĞ¾ĞºĞ¸Ğ¹ Ğ¿Ğ¾Ñ€Ğ¾Ğ³ automation_score ({discovery.config['min_automation_score']})")
        print(f"   - ĞĞµÑ‚ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ³Ñ€ÑƒĞ¿Ğ¿")
        print(f"   - Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")

if __name__ == "__main__":
    main() 